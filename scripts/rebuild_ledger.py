import sys
import os
import logging
import argparse
from datetime import datetime
from typing import Dict, List, Any, Tuple

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))

from services.data_service import DataService
from core.enums import DataCategory, StockMovementType, MaterialType

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

def rebuild_ledger(run: bool = False):
    """
    é‡æ„è„šæœ¬ï¼šæ¸…ç©ºå½“å‰åº“å­˜æµæ°´ï¼Œæ ¹æ®æºå•æ®é‡æ–°ç”Ÿæˆã€‚
    """
    logger.info("=" * 60)
    logger.info("ğŸ› ï¸ å¼€å§‹æ‰§è¡Œè´¦æœ¬å½»åº•é‡æ„")
    logger.info(f"æ‰§è¡Œæ¨¡å¼: {'æ­£å¼æ‰§è¡Œ' if run else 'é¢„è§ˆæ¨¡å¼'}")
    logger.info("=" * 60)
    
    logger.warning("âš ï¸ è­¦å‘Šï¼šæ‰‹åŠ¨ç›˜ç‚¹è®°å½• (ADJUST) å°†ä¼šä¸¢å¤±ï¼Œå› ä¸ºå®ƒä»¬æ²¡æœ‰æºå•æ®æ”¯æ’‘ã€‚")
    
    ds = DataService()
    data = ds.load_data()
    
    if run:
        logger.info("æ­£åœ¨åˆ›å»ºå®‰å…¨å¤‡ä»½...")
        ds.create_backup()

    # --- 1. æ¸…é›¶é˜¶æ®µ ---
    logger.info("\n[1/5] æ¸…é›¶é˜¶æ®µ (Reset)...")
    
    raw_materials = data.get(DataCategory.RAW_MATERIALS.value, [])
    for m in raw_materials:
        m["stock_quantity"] = 0.0
        m["last_stock_update"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
    product_inventory = data.get(DataCategory.PRODUCT_INVENTORY.value, [])
    for p in product_inventory:
        p["stock_quantity"] = 0.0
        if "current_stock" in p:
            p["current_stock"] = 0.0
        p["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
    # æ¸…ç©ºæµæ°´
    data[DataCategory.INVENTORY_RECORDS.value] = []
    data[DataCategory.PRODUCT_INVENTORY_RECORDS.value] = []
    
    inv_records = data[DataCategory.INVENTORY_RECORDS.value]
    prod_records = data[DataCategory.PRODUCT_INVENTORY_RECORDS.value]
    
    # è¾…åŠ©å·¥å…·ï¼šè·å–ä¸‹ä¸€ä¸ª ID
    def get_next_inv_id():
        return len(inv_records) + 1
    def get_next_prod_id():
        return len(prod_records) + 1

    # å»ºç«‹ BOM æ˜ å°„
    boms = data.get("boms", [])
    bom_map = {}
    for b in boms:
        # æ‹¼æ¥äº§å“åç§°ï¼Œå¦‚ ST-60A
        full_name = f"{b.get('bom_code')}-{b.get('bom_name')}"
        bom_map[b.get("id")] = full_name

    # --- 2. é‡æ”¾ï¼šåŸææ–™å…¥åº“ (Replay Raw Material In) ---
    logger.info("[2/5] é‡æ”¾ï¼šåŸææ–™å…¥åº“ (Goods Receipts)...")
    goods_receipts = data.get(DataCategory.GOODS_RECEIPTS.value, [])
    gr_count = 0
    for gr in goods_receipts:
        if gr.get("status") not in ["completed", "received"]:
            continue
            
        for item in gr.get("items", []):
            mid = item.get("material_id")
            qty = float(item.get("quantity", 0.0))
            
            # å¼ºåˆ¶è§„åˆ™ï¼šå¦‚æœæ•°é‡å¾ˆå°ä¸”æ²¡æœ‰æ˜ç¡®å•ä½ï¼Œæˆ–è€… remark æç¤ºæ˜¯å¨ï¼Œåˆ™ * 1000
            # è¿™é‡Œç®€å•åˆ¤æ–­ï¼šå¦‚æœæ•°é‡ < 100 ä¸”ç‰©æ–™æ˜¯åŸææ–™ï¼Œæå¤§æ¦‚ç‡æ˜¯å¨
            remark = item.get("remark", "").lower()
            if qty < 100.0 or "ton" in remark or "å¨" in remark:
                qty *= 1000.0
                
            inv_records.append({
                "id": get_next_inv_id(),
                "material_id": mid,
                "type": StockMovementType.IN.value,
                "quantity": qty,
                "unit": "kg",
                "reason": f"é‡‡è´­å…¥åº“ (å•å·: {gr.get('receipt_code')})",
                "date": gr.get("date"),
                "created_at": gr.get("created_at"),
                "related_doc_type": "GOODS_RECEIPT",
                "related_doc_id": gr.get("id")
            })
            
            # æ›´æ–°åº“å­˜
            for m in raw_materials:
                if m["id"] == mid:
                    m["stock_quantity"] += qty
                    break
            gr_count += 1
    logger.info(f"   - å·²é‡æ”¾ {gr_count} æ¡å…¥åº“æ˜ç»†ã€‚")

    # --- 3. é‡æ”¾ï¼šç”Ÿäº§æ¶ˆè€— (Replay Consumption) ---
    logger.info("[3/5] é‡æ”¾ï¼šç”Ÿäº§æ¶ˆè€— (Material Issues)...")
    material_issues = data.get(DataCategory.MATERIAL_ISSUES.value, [])
    issue_count = 0
    for issue in material_issues:
        if issue.get("status") != "posted":
            continue
            
        for line in issue.get("lines", []):
            item_id = line.get("item_id")
            item_type = line.get("item_type", MaterialType.RAW_MATERIAL.value)
            qty = float(line.get("required_qty", 0.0))
            
            if item_type == MaterialType.PRODUCT.value:
                # æ‰£å‡æˆå“åº“å­˜ (åŸºå‡†: å¨)
                # å¦‚æœå•æ®ä¸Šæ˜¯ kgï¼Œåˆ™ / 1000
                if line.get("uom") == "kg":
                    qty /= 1000.0
                    
                prod_records.append({
                    "id": get_next_prod_id(),
                    "product_name": line.get("item_name"),
                    "type": StockMovementType.CONSUME_OUT.value,
                    "quantity": qty,
                    "unit": "ton",
                    "reason": f"ç”Ÿäº§é¢†æ–™ (å•å·: {issue.get('issue_code')})",
                    "date": issue.get("posted_at", "").split(" ")[0],
                    "created_at": issue.get("posted_at"),
                    "related_doc_type": "MATERIAL_ISSUE",
                    "related_doc_id": issue.get("id")
                })
                # æ›´æ–°åº“å­˜
                for p in product_inventory:
                    if p.get("id") == item_id or p.get("product_name") == line.get("item_name"):
                        p["stock_quantity"] -= qty
                        if "current_stock" in p: p["current_stock"] -= qty
                        break
            else:
                # æ‰£å‡åŸææ–™åº“å­˜ (åŸºå‡†: kg)
                inv_records.append({
                    "id": get_next_inv_id(),
                    "material_id": item_id,
                    "type": StockMovementType.CONSUME_OUT.value,
                    "quantity": qty,
                    "unit": "kg",
                    "reason": f"ç”Ÿäº§é¢†æ–™ (å•å·: {issue.get('issue_code')})",
                    "date": issue.get("posted_at", "").split(" ")[0],
                    "created_at": issue.get("posted_at"),
                    "related_doc_type": "MATERIAL_ISSUE",
                    "related_doc_id": issue.get("id")
                })
                # æ›´æ–°åº“å­˜
                for m in raw_materials:
                    if m["id"] == item_id:
                        m["stock_quantity"] -= qty
                        break
            issue_count += 1
    logger.info(f"   - å·²é‡æ”¾ {issue_count} æ¡é¢†æ–™æ˜ç»†ã€‚")

    # --- 4. é‡æ”¾ï¼šç”Ÿäº§äº§å‡º (Replay Production) ---
    logger.info("[4/5] é‡æ”¾ï¼šç”Ÿäº§äº§å‡º (Production Orders)...")
    production_orders = data.get(DataCategory.PRODUCTION_ORDERS.value, [])
    prod_order_count = 0
    for order in production_orders:
        if order.get("status") != "finished":
            continue
            
        qty = float(order.get("actual_quantity") or order.get("plan_qty") or 0.0)
        # å¼ºåˆ¶è§„åˆ™ï¼šå¦‚æœæ•°é‡ > 100 ä¸”å•ä½æ˜¯æˆå“ï¼Œæå¤§æ¦‚ç‡åŸå•å¡«çš„æ˜¯ kg
        if qty > 100.0:
            qty /= 1000.0
            
        p_name = order.get("product_name") or bom_map.get(order.get("bom_id"))
        if not p_name:
            logger.warning(f"     [è·³è¿‡] ç”Ÿäº§è®¢å• {order.get('order_code')} ç¼ºå°‘äº§å“åç§°ä¸”æ— æ³•é€šè¿‡ BOM å…³è”ã€‚")
            continue
            
        # æŸ¥æ‰¾æˆ–åˆ›å»ºæˆå“
        target_p = next((p for p in product_inventory if p.get("product_name") == p_name), None)
        if not target_p:
            new_p_id = len(product_inventory) + 1
            target_p = {
                "id": new_p_id,
                "product_name": p_name,
                "stock_quantity": 0.0,
                "unit": "å¨"
            }
            product_inventory.append(target_p)
            logger.info(f"     [è‡ªåŠ¨åˆ›å»ºæˆå“] {p_name}")

        prod_records.append({
            "id": get_next_prod_id(),
            "product_name": p_name,
            "type": StockMovementType.PRODUCE_IN.value,
            "quantity": qty,
            "unit": "ton",
            "reason": f"ç”Ÿäº§å®Œå·¥ (å•å·: {order.get('order_code')})",
            "date": order.get("finished_at", "").split(" ")[0],
            "created_at": order.get("finished_at"),
            "related_doc_type": "PRODUCTION_ORDER",
            "related_doc_id": order.get("id")
        })
        # æ›´æ–°åº“å­˜
        target_p["stock_quantity"] += qty
        if "current_stock" in target_p: target_p["current_stock"] += qty
        prod_order_count += 1
    logger.info(f"   - å·²é‡æ”¾ {prod_order_count} ä¸ªç”Ÿäº§è®¢å•ã€‚")

    # --- 5. é‡æ”¾ï¼šå‘è´§å‡ºåº“ (Replay Shipping) ---
    logger.info("[5/5] é‡æ”¾ï¼šå‘è´§å‡ºåº“ (Shipping Orders)...")
    shipping_orders = data.get(DataCategory.SHIPPING_ORDERS.value, [])
    ship_count = 0
    for ship in shipping_orders:
        if ship.get("status") not in ["shipped", "completed"]:
            continue
            
        for item in ship.get("items", []):
            p_name = item.get("product_name")
            qty = float(item.get("quantity", 0.0))
            
            # å¼ºåˆ¶è§„åˆ™ï¼šå¦‚æœæ•°é‡ > 100ï¼Œæå¤§æ¦‚ç‡æ˜¯ kg
            if qty > 100.0:
                qty /= 1000.0
                
            prod_records.append({
                "id": get_next_prod_id(),
                "product_name": p_name,
                "type": StockMovementType.SHIP_OUT.value,
                "quantity": qty,
                "unit": "ton",
                "reason": f"é”€å”®å‘è´§ (å•å·: {ship.get('shipping_code')})",
                "date": ship.get("date"),
                "created_at": ship.get("created_at"),
                "related_doc_type": "SHIPPING_ORDER",
                "related_doc_id": ship.get("id")
            })
            
            # æ›´æ–°åº“å­˜
            for p in product_inventory:
                if p.get("product_name") == p_name:
                    p["stock_quantity"] -= qty
                    if "current_stock" in p: p["current_stock"] -= qty
                    break
            ship_count += 1
    logger.info(f"   - å·²é‡æ”¾ {ship_count} æ¡å‘è´§æ˜ç»†ã€‚")

    # --- æ€»ç»“ä¸ä¿å­˜ ---
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ é‡æ„å®Œæˆï¼")
    logger.info(f"- ç”ŸæˆåŸææ–™æµæ°´: {len(inv_records)} æ¡")
    logger.info(f"- ç”Ÿæˆæˆå“æµæ°´: {len(prod_records)} æ¡")
    
    if run:
        logger.info("æ­£åœ¨ä¿å­˜ç»“æœåˆ°æ•°æ®åº“...")
        if ds.save_data(data):
            logger.info("âœ… è´¦æœ¬é‡æ„æˆåŠŸï¼æ‰€æœ‰åº“å­˜å·²æ ¹æ®æºå•æ®å¯¹é½ã€‚")
        else:
            logger.error("âŒ ä¿å­˜å¤±è´¥ã€‚")
    else:
        logger.info("\næ³¨æ„ï¼šå½“å‰ä¸ºé¢„è§ˆæ¨¡å¼ï¼Œæœªå†™å…¥æ–‡ä»¶ã€‚")
        logger.info("ç¡®è®¤é€»è¾‘æ— è¯¯åï¼Œè¯·æ‰§è¡Œ: python scripts/rebuild_ledger.py --run")
    logger.info("=" * 60)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è´¦æœ¬é‡æ„è„šæœ¬")
    parser.add_argument("--run", action="store_true", help="æ‰§è¡Œä¿å­˜æ“ä½œ")
    args = parser.parse_args()
    
    rebuild_ledger(run=args.run)
